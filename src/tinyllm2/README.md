# tinyllm2

Based on:
- [ゼロから始める自作LLM｜Masayuki Abe](https://note.com/masayuki_abe/n/n365b500d91d2)
- [speed1313/jax-llm: JAX implementation of Large Language Models. You can train GPT-2-like model with 青空文庫 (aozora bunko-clean dataset) or any other text dataset. (github.com)

